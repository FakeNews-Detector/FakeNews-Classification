{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iuV8AfIIxN12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c46afe6b-ce29-43f4-a2d4-3fde934ed415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PySastrawi\n",
            "  Downloading PySastrawi-1.2.0-py2.py3-none-any.whl (210 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 210 kB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: PySastrawi\n",
            "Successfully installed PySastrawi-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install PySastrawi\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import Sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X10McqK9xdP"
      },
      "source": [
        "# Scrapping Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvnP4TNTZXxE"
      },
      "outputs": [],
      "source": [
        "#scrapping news\n",
        "import bs4\n",
        "URL = \"https://turnbackhoax.id/category/fitnah-hasut-hoax/page/\"\n",
        "upperframe = []\n",
        "\n",
        "for page in range(1,421):\n",
        "  data = []\n",
        "  req = requests.get(URL + str(page) + \"/\")\n",
        "  soup = BeautifulSoup(req.text, \"html.parser\")\n",
        "\n",
        "  coverpage_news = soup.find_all(\"h3\", attrs = {\"class\" : \"entry-title mh-loop-title\"})\n",
        "  for j in coverpage_news:\n",
        "    judul = j.find(\"a\").get_text().strip()\n",
        "    link = j.find(\"a\")[\"href\"].strip()\n",
        "    data.append([judul, link])\n",
        "  upperframe.extend(data)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l1Zgeopd_Tc"
      },
      "outputs": [],
      "source": [
        "#create dataframe for scrapping news\n",
        "data = pd.DataFrame(upperframe, columns=[\"judul\",\"link\"])\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iMhQehql3hh"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pd-XFNyZpKB"
      },
      "outputs": [],
      "source": [
        "real_train = pd.read_excel(\"real_train.xlsx\")\n",
        "real_test = pd.read_excel(\"real_testing.xlsx\")\n",
        "fake_train = pd.read_excel(\"fake_train.xlsx\")\n",
        "fake_test = pd.read_excel(\"fake_testing.xlsx\")\n",
        "test = pd.read_csv(\"Data_latih.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_CoLzcHZpKz"
      },
      "source": [
        "Data Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V6mDqRkmEQc",
        "outputId": "a21ec1f3-d862-44ec-8d3c-6686ddcf1af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpP0sXOhZpK9"
      },
      "outputs": [],
      "source": [
        "real_train[\"label\"] = 0\n",
        "real_test[\"label\"] = 0\n",
        "fake_train[\"label\"] = 1\n",
        "fake_test[\"label\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgsFnUbPZpLE"
      },
      "outputs": [],
      "source": [
        "train = pd.concat([real_train, fake_train], ignore_index=True)\n",
        "validation = pd.concat([real_test, fake_test], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyqaPcCZZpLI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "ab9c0c7b-4ed4-4a59-cf2f-a3229f2bd2d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               judul  \\\n",
              "0  jelang tutup tahun diler mobil sebar diskon ha...   \n",
              "1        tabir harga suv maserati dibuka tahun depan   \n",
              "2      tampang skutik honda air blade dirombak total   \n",
              "3  sinarmas hana finance incar mobil bekas ekspat...   \n",
              "4  orang kaya di indonesia terintimidasi harga ha...   \n",
              "5      mazda punya bengkel bodi dan cat di tangerang   \n",
              "6          menunggangi godzilla di sirkuit sodegaura   \n",
              "7      mimpi nissan ciptakan mobil yang bisa ngobrol   \n",
              "8            pandji pragiwaksono jajal bisnis online   \n",
              "9  rabu sore nilai tukar ditutup melemah jadi rp ...   \n",
              "\n",
              "                                                link kategori  label  \\\n",
              "0  http://www.tribunnews.com/otomotif/2015/12/09/...    Valid      0   \n",
              "1  http://www.tribunnews.com/otomotif/2015/12/09/...    Valid      0   \n",
              "2  http://www.tribunnews.com/otomotif/2015/12/09/...    Valid      0   \n",
              "3  http://www.tribunnews.com/otomotif/2015/12/09/...    Valid      0   \n",
              "4  http://www.tribunnews.com/otomotif/2015/12/09/...    Valid      0   \n",
              "5  http://www.tribunnews.com/otomotif/2015/12/09/...    Valid      0   \n",
              "6  http://www.tribunnews.com/otomotif/2015/12/09/...    Valid      0   \n",
              "7  http://www.tribunnews.com/otomotif/2015/12/09/...    Valid      0   \n",
              "8  http://www.tribunnews.com/bisnis/2015/12/09/pa...    Valid      0   \n",
              "9  http://www.tribunnews.com/bisnis/2015/12/09/ra...    Valid      0   \n",
              "\n",
              "                                          judul_baru  \n",
              "0  [jelang, tutup, diler, mobil, sebar, diskon, h...  \n",
              "1              [tabir, harga, suv, maserati, dibuka]  \n",
              "2  [tampang, skutik, honda, air, blade, dirombak,...  \n",
              "3  [sinarmas, hana, finance, incar, mobil, bekas,...  \n",
              "4  [orang, kaya, indonesia, terintimidasi, harga,...  \n",
              "5             [mazda, bengkel, bodi, cat, tangerang]  \n",
              "6        [menunggangi, godzilla, sirkuit, sodegaura]  \n",
              "7          [mimpi, nissan, ciptakan, mobil, ngobrol]  \n",
              "8      [pandji, pragiwaksono, jajal, bisnis, online]  \n",
              "9  [rabu, sore, nilai, tukar, ditutup, melemah, d...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c1ca464-1d2d-4696-ac56-41a95baf2147\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>judul</th>\n",
              "      <th>link</th>\n",
              "      <th>kategori</th>\n",
              "      <th>label</th>\n",
              "      <th>judul_baru</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jelang tutup tahun diler mobil sebar diskon ha...</td>\n",
              "      <td>http://www.tribunnews.com/otomotif/2015/12/09/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[jelang, tutup, diler, mobil, sebar, diskon, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tabir harga suv maserati dibuka tahun depan</td>\n",
              "      <td>http://www.tribunnews.com/otomotif/2015/12/09/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[tabir, harga, suv, maserati, dibuka]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tampang skutik honda air blade dirombak total</td>\n",
              "      <td>http://www.tribunnews.com/otomotif/2015/12/09/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[tampang, skutik, honda, air, blade, dirombak,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sinarmas hana finance incar mobil bekas ekspat...</td>\n",
              "      <td>http://www.tribunnews.com/otomotif/2015/12/09/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[sinarmas, hana, finance, incar, mobil, bekas,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>orang kaya di indonesia terintimidasi harga ha...</td>\n",
              "      <td>http://www.tribunnews.com/otomotif/2015/12/09/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[orang, kaya, indonesia, terintimidasi, harga,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>mazda punya bengkel bodi dan cat di tangerang</td>\n",
              "      <td>http://www.tribunnews.com/otomotif/2015/12/09/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[mazda, bengkel, bodi, cat, tangerang]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>menunggangi godzilla di sirkuit sodegaura</td>\n",
              "      <td>http://www.tribunnews.com/otomotif/2015/12/09/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[menunggangi, godzilla, sirkuit, sodegaura]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>mimpi nissan ciptakan mobil yang bisa ngobrol</td>\n",
              "      <td>http://www.tribunnews.com/otomotif/2015/12/09/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[mimpi, nissan, ciptakan, mobil, ngobrol]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>pandji pragiwaksono jajal bisnis online</td>\n",
              "      <td>http://www.tribunnews.com/bisnis/2015/12/09/pa...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[pandji, pragiwaksono, jajal, bisnis, online]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>rabu sore nilai tukar ditutup melemah jadi rp ...</td>\n",
              "      <td>http://www.tribunnews.com/bisnis/2015/12/09/ra...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[rabu, sore, nilai, tukar, ditutup, melemah, d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c1ca464-1d2d-4696-ac56-41a95baf2147')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c1ca464-1d2d-4696-ac56-41a95baf2147 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c1ca464-1d2d-4696-ac56-41a95baf2147');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "#Preprocessing data training\n",
        "#remove punctuation\n",
        "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "def remove_punctuation(text):\n",
        "    no_punct = \"\".join([i for i in text if i not in punc])\n",
        "    return no_punct\n",
        "\n",
        "train['judul'] = train['judul'].apply(lambda x: remove_punctuation(x))\n",
        "\n",
        "#lowering text\n",
        "train['judul'] = train['judul'].apply(lambda x: x.lower())\n",
        "\n",
        "#remove number\n",
        "def remove_number(text):\n",
        "    no_number = re.sub(r'\\d', '', text)\n",
        "    return no_number\n",
        "\n",
        "train['judul'] = train['judul'].apply(lambda x: remove_number(x))\n",
        "\n",
        "#remove emoji\n",
        "train[\"judul\"] = train[\"judul\"].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))\n",
        "\n",
        "#remove whitespace\n",
        "# def remove_whitespace(text):\n",
        "#     if len(text.split()) > 1:\n",
        "#         result = ' '.join(text.split())\n",
        "#         return result\n",
        "\n",
        "# df['judul'] = df['judul'].apply(remove_whitespace)\n",
        "# df.head(10)\n",
        "\n",
        "#define stemming\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "#define stopwords\n",
        "stopword = stopwords.words('indonesian')\n",
        "stopword.extend([\"c\", \"rp\", \"di\", \"ok\", \"tak\", \"r\", \"x\", \"i\", \"ini\", \"jadi\", \"ada\", \"ke\", \"dan\", \"akan\", \n",
        "\"sang\", \"yang\", \"ada\", \"bagi\", \"untuk\", \"pada\", \"dengan\", \"saat\", \"tidak\", \"nak\", \"tapi\", \"buat\", \"semua\",\n",
        "\"dari\", \"ingin\", \"gara\", \"saat\", \"anak\", \"hey\", \"bro\"])\n",
        "\n",
        "def clean_text(text, stem=False):\n",
        "    tokens = []\n",
        "    for token in text.split():\n",
        "        if token not in stopword:\n",
        "            if stem:\n",
        "                tokens.append(stemmer.stem(token))\n",
        "            else:\n",
        "                tokens.append(token)\n",
        "    return tokens\n",
        "\n",
        "train['judul_baru'] = train['judul'].apply(lambda x: clean_text(x))\n",
        "train.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzdGrrL6ZpMM"
      },
      "source": [
        "Data validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19XuRS4-ZpMR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "4e2d2d52-5741-48b8-b95f-bb2514aa4be7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               judul  \\\n",
              "0  terima rekomendasi bawaslu kpu buka kembali pe...   \n",
              "1  jokowi lantik sembilan komisioner komisi kejak...   \n",
              "2  surat pengunduran diri gus mus ditulistangan h...   \n",
              "3  bnpb abu vulkanik gunung raung ke selatantengg...   \n",
              "4  sempat gagal pan berencana ajukan calon lagi l...   \n",
              "5  bnn musnahkan puluhan ribu gram sabu dan ratus...   \n",
              "6  kabareskrim kaji adanya laporan soal penculika...   \n",
              "7  kpk dipolisikan terkait penculikan oc kaligis ...   \n",
              "8  saat rekonstruksi pelaku pembunuhan dan pembak...   \n",
              "9  setelah pertemuan dengan mui bpjs kesehatan ti...   \n",
              "\n",
              "                                                link kategori  label  \\\n",
              "0  http://www.tribunnews.com/nasional/2015/08/06/...    Valid      0   \n",
              "1  http://www.tribunnews.com/nasional/2015/08/06/...    Valid      0   \n",
              "2  http://www.tribunnews.com/nasional/2015/08/06/...    Valid      0   \n",
              "3  http://www.tribunnews.com/nasional/2015/08/06/...    Valid      0   \n",
              "4  http://www.tribunnews.com/nasional/2015/08/06/...    Valid      0   \n",
              "5  http://www.tribunnews.com/nasional/2015/08/06/...    Valid      0   \n",
              "6  http://www.tribunnews.com/nasional/2015/08/06/...    Valid      0   \n",
              "7  http://www.tribunnews.com/nasional/2015/08/06/...    Valid      0   \n",
              "8  http://www.tribunnews.com/nasional/2015/08/06/...    Valid      0   \n",
              "9  http://www.tribunnews.com/nasional/2015/08/06/...    Valid      0   \n",
              "\n",
              "                                          judul_baru  \n",
              "0  [terima, rekomendasi, bawaslu, kpu, buka, pend...  \n",
              "1  [jokowi, lantik, sembilan, komisioner, komisi,...  \n",
              "2  [surat, pengunduran, gus, mus, ditulistangan, ...  \n",
              "3  [bnpb, abu, vulkanik, gunung, raung, selatante...  \n",
              "4  [gagal, pan, berencana, ajukan, calon, lawan, ...  \n",
              "5  [bnn, musnahkan, puluhan, ribu, gram, sabu, ra...  \n",
              "6  [kabareskrim, kaji, laporan, penculikan, oc, k...  \n",
              "7  [kpk, dipolisikan, terkait, penculikan, oc, ka...  \n",
              "8  [rekonstruksi, pelaku, pembunuhan, pembakaran,...  \n",
              "9           [pertemuan, mui, bpjs, kesehatan, haram]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-926e5b44-1cce-450f-bfbe-7170db0f6e9b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>judul</th>\n",
              "      <th>link</th>\n",
              "      <th>kategori</th>\n",
              "      <th>label</th>\n",
              "      <th>judul_baru</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>terima rekomendasi bawaslu kpu buka kembali pe...</td>\n",
              "      <td>http://www.tribunnews.com/nasional/2015/08/06/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[terima, rekomendasi, bawaslu, kpu, buka, pend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jokowi lantik sembilan komisioner komisi kejak...</td>\n",
              "      <td>http://www.tribunnews.com/nasional/2015/08/06/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[jokowi, lantik, sembilan, komisioner, komisi,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>surat pengunduran diri gus mus ditulistangan h...</td>\n",
              "      <td>http://www.tribunnews.com/nasional/2015/08/06/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[surat, pengunduran, gus, mus, ditulistangan, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bnpb abu vulkanik gunung raung ke selatantengg...</td>\n",
              "      <td>http://www.tribunnews.com/nasional/2015/08/06/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[bnpb, abu, vulkanik, gunung, raung, selatante...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sempat gagal pan berencana ajukan calon lagi l...</td>\n",
              "      <td>http://www.tribunnews.com/nasional/2015/08/06/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[gagal, pan, berencana, ajukan, calon, lawan, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>bnn musnahkan puluhan ribu gram sabu dan ratus...</td>\n",
              "      <td>http://www.tribunnews.com/nasional/2015/08/06/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[bnn, musnahkan, puluhan, ribu, gram, sabu, ra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>kabareskrim kaji adanya laporan soal penculika...</td>\n",
              "      <td>http://www.tribunnews.com/nasional/2015/08/06/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[kabareskrim, kaji, laporan, penculikan, oc, k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>kpk dipolisikan terkait penculikan oc kaligis ...</td>\n",
              "      <td>http://www.tribunnews.com/nasional/2015/08/06/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[kpk, dipolisikan, terkait, penculikan, oc, ka...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>saat rekonstruksi pelaku pembunuhan dan pembak...</td>\n",
              "      <td>http://www.tribunnews.com/nasional/2015/08/06/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[rekonstruksi, pelaku, pembunuhan, pembakaran,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>setelah pertemuan dengan mui bpjs kesehatan ti...</td>\n",
              "      <td>http://www.tribunnews.com/nasional/2015/08/06/...</td>\n",
              "      <td>Valid</td>\n",
              "      <td>0</td>\n",
              "      <td>[pertemuan, mui, bpjs, kesehatan, haram]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-926e5b44-1cce-450f-bfbe-7170db0f6e9b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-926e5b44-1cce-450f-bfbe-7170db0f6e9b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-926e5b44-1cce-450f-bfbe-7170db0f6e9b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "#remove punctuation\n",
        "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "def remove_punctuation(text):\n",
        "    no_punct = \"\".join([i for i in text if i not in punc])\n",
        "    return no_punct\n",
        "\n",
        "validation['judul'] = validation['judul'].apply(lambda x: remove_punctuation(x))\n",
        "\n",
        "#lowering text\n",
        "validation['judul'] = validation['judul'].apply(lambda x: x.lower())\n",
        "\n",
        "#remove number\n",
        "def remove_number(text):\n",
        "    no_number = re.sub(r'\\d', '', text)\n",
        "    return no_number\n",
        "\n",
        "validation['judul'] = validation['judul'].apply(lambda x: remove_number(x))\n",
        "\n",
        "#remove emoji\n",
        "validation[\"judul\"] = validation[\"judul\"].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))\n",
        "\n",
        "#define stemming\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "#define stopwords\n",
        "stopword = stopwords.words('indonesian')\n",
        "stopword.extend([\"c\", \"rp\", \"di\", \"ok\", \"tak\", \"r\", \"x\", \"i\", \"ini\", \"jadi\", \"ada\", \"ke\", \"dan\", \"akan\", \n",
        "\"sang\", \"yang\", \"ada\", \"bagi\", \"untuk\", \"pada\", \"dengan\", \"saat\", \"tidak\", \"nak\", \"tapi\", \"buat\", \"semua\",\n",
        "\"dari\", \"ingin\", \"gara\", \"saat\", \"anak\", \"hey\", \"bro\"])\n",
        "\n",
        "def clean_text(text, stem=False):\n",
        "    tokens = []\n",
        "    for token in text.split():\n",
        "        if token not in stopword:\n",
        "            if stem:\n",
        "                tokens.append(stemmer.stem(token))\n",
        "            else:\n",
        "                tokens.append(token)\n",
        "    return tokens\n",
        "\n",
        "validation['judul_baru'] = validation['judul'].apply(lambda x: clean_text(x))\n",
        "\n",
        "validation.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUXip0RwZpN6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "outputId": "359e875b-02e2-4edd-f91e-e340e6c1aae8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     ID  label    tanggal                                              judul  \\\n",
              "0    71      1  17-Aug-20  pemakaian masker menyebabkan penyakit legionna...   \n",
              "1   461      1  17-Jul-20  instruksi gubernur jateng tentang penilangan  ...   \n",
              "2   495      1  13-Jul-20  foto jim rohn jokowi adalah presiden terbaik d...   \n",
              "3   550      1   8-Jul-20  ini bukan politik tapi kenyataan pak jokowi be...   \n",
              "4   681      1  24-Jun-20       foto kadrun kalo lihat foto ini panas dingin   \n",
              "5   736      1  17-Jun-20  event promo smartphone jne  spesial di bulan juni   \n",
              "6  1161      1   5-May-20  mereka sudah mempersiapkan diri dengan baik un...   \n",
              "7  1597      1  24-Mar-20  foto presiden italia menangis karena tak cukup...   \n",
              "8  2098      1   9-Jan-20  kapolres timor tengah utara  nusa tenggara tim...   \n",
              "9  2226      1  24-Dec-19  video polisi china telah menganiaya wanita uig...   \n",
              "\n",
              "                                              narasi nama file gambar  \\\n",
              "0  A caller to a radio talk show recently shared ...           71.jpg   \n",
              "1  Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...          461.png   \n",
              "2  Jokowi adalah presiden terbaik dlm sejarah ban...          495.png   \n",
              "3  Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...          550.png   \n",
              "4        Kadrun kalo lihat foto ini panas dingin . .          681.jpg   \n",
              "5  selamat siang teman teman fb ku semuanyaü§©,cuma...          736.png   \n",
              "6  LIHATLAH MEREKA SUDAH MEMPERSIAPKAN DIRI DENGA...         1161.png   \n",
              "7  Italia punya fasilitas perawatan kesehatan ter...         1597.png   \n",
              "8  Polisi goblok. Bukanya cpet‚Äù d tolongin malah ...         2098.jpg   \n",
              "9  Polisi china telah menganiaya wanita uighur le...         2226.png   \n",
              "\n",
              "                                          judul_baru  \n",
              "0  [pemakaian, masker, menyebabkan, penyakit, leg...  \n",
              "1  [instruksi, gubernur, jateng, penilangan, yg, ...  \n",
              "2  [foto, jim, rohn, jokowi, presiden, terbaik, d...  \n",
              "3  [politik, kenyataan, jokowi, berhasil, memulan...  \n",
              "4   [foto, kadrun, kalo, lihat, foto, panas, dingin]  \n",
              "5     [event, promo, smartphone, jne, spesial, juni]  \n",
              "6                                 [menguasai, negri]  \n",
              "7  [foto, presiden, italia, menangis, lahan, meng...  \n",
              "8  [kapolres, timor, utara, nusa, tenggara, timur...  \n",
              "9  [video, polisi, china, menganiaya, wanita, uig...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02ef1046-ea85-4862-9768-90a4ef5023ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>label</th>\n",
              "      <th>tanggal</th>\n",
              "      <th>judul</th>\n",
              "      <th>narasi</th>\n",
              "      <th>nama file gambar</th>\n",
              "      <th>judul_baru</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>71</td>\n",
              "      <td>1</td>\n",
              "      <td>17-Aug-20</td>\n",
              "      <td>pemakaian masker menyebabkan penyakit legionna...</td>\n",
              "      <td>A caller to a radio talk show recently shared ...</td>\n",
              "      <td>71.jpg</td>\n",
              "      <td>[pemakaian, masker, menyebabkan, penyakit, leg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>461</td>\n",
              "      <td>1</td>\n",
              "      <td>17-Jul-20</td>\n",
              "      <td>instruksi gubernur jateng tentang penilangan  ...</td>\n",
              "      <td>Yth.Seluruh Anggota Grup Sesuai Instruksi Gube...</td>\n",
              "      <td>461.png</td>\n",
              "      <td>[instruksi, gubernur, jateng, penilangan, yg, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>495</td>\n",
              "      <td>1</td>\n",
              "      <td>13-Jul-20</td>\n",
              "      <td>foto jim rohn jokowi adalah presiden terbaik d...</td>\n",
              "      <td>Jokowi adalah presiden terbaik dlm sejarah ban...</td>\n",
              "      <td>495.png</td>\n",
              "      <td>[foto, jim, rohn, jokowi, presiden, terbaik, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>550</td>\n",
              "      <td>1</td>\n",
              "      <td>8-Jul-20</td>\n",
              "      <td>ini bukan politik tapi kenyataan pak jokowi be...</td>\n",
              "      <td>Maaf Mas2 dan Mbak2, ini bukan politik, tapi k...</td>\n",
              "      <td>550.png</td>\n",
              "      <td>[politik, kenyataan, jokowi, berhasil, memulan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>681</td>\n",
              "      <td>1</td>\n",
              "      <td>24-Jun-20</td>\n",
              "      <td>foto kadrun kalo lihat foto ini panas dingin</td>\n",
              "      <td>Kadrun kalo lihat foto ini panas dingin . .</td>\n",
              "      <td>681.jpg</td>\n",
              "      <td>[foto, kadrun, kalo, lihat, foto, panas, dingin]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>736</td>\n",
              "      <td>1</td>\n",
              "      <td>17-Jun-20</td>\n",
              "      <td>event promo smartphone jne  spesial di bulan juni</td>\n",
              "      <td>selamat siang teman teman fb ku semuanyaü§©,cuma...</td>\n",
              "      <td>736.png</td>\n",
              "      <td>[event, promo, smartphone, jne, spesial, juni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1161</td>\n",
              "      <td>1</td>\n",
              "      <td>5-May-20</td>\n",
              "      <td>mereka sudah mempersiapkan diri dengan baik un...</td>\n",
              "      <td>LIHATLAH MEREKA SUDAH MEMPERSIAPKAN DIRI DENGA...</td>\n",
              "      <td>1161.png</td>\n",
              "      <td>[menguasai, negri]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1597</td>\n",
              "      <td>1</td>\n",
              "      <td>24-Mar-20</td>\n",
              "      <td>foto presiden italia menangis karena tak cukup...</td>\n",
              "      <td>Italia punya fasilitas perawatan kesehatan ter...</td>\n",
              "      <td>1597.png</td>\n",
              "      <td>[foto, presiden, italia, menangis, lahan, meng...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2098</td>\n",
              "      <td>1</td>\n",
              "      <td>9-Jan-20</td>\n",
              "      <td>kapolres timor tengah utara  nusa tenggara tim...</td>\n",
              "      <td>Polisi goblok. Bukanya cpet‚Äù d tolongin malah ...</td>\n",
              "      <td>2098.jpg</td>\n",
              "      <td>[kapolres, timor, utara, nusa, tenggara, timur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2226</td>\n",
              "      <td>1</td>\n",
              "      <td>24-Dec-19</td>\n",
              "      <td>video polisi china telah menganiaya wanita uig...</td>\n",
              "      <td>Polisi china telah menganiaya wanita uighur le...</td>\n",
              "      <td>2226.png</td>\n",
              "      <td>[video, polisi, china, menganiaya, wanita, uig...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02ef1046-ea85-4862-9768-90a4ef5023ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02ef1046-ea85-4862-9768-90a4ef5023ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02ef1046-ea85-4862-9768-90a4ef5023ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# data testing\n",
        "#remove punctuation\n",
        "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "def remove_punctuation(text):\n",
        "    no_punct = \"\".join([i for i in text if i not in punc])\n",
        "    return no_punct\n",
        "\n",
        "test['judul'] = test['judul'].apply(lambda x: remove_punctuation(x))\n",
        "\n",
        "#lowering text\n",
        "test['judul'] = test['judul'].apply(lambda x: x.lower())\n",
        "\n",
        "#remove number\n",
        "def remove_number(text):\n",
        "    no_number = re.sub(r'\\d', '', text)\n",
        "    return no_number\n",
        "\n",
        "test['judul'] = test['judul'].apply(lambda x: remove_number(x))\n",
        "\n",
        "#remove emoji\n",
        "test[\"judul\"] = test[\"judul\"].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))\n",
        "\n",
        "#define stemming\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "#define stopwords\n",
        "stopword = stopwords.words('indonesian')\n",
        "stopword.extend([\"c\", \"rp\", \"di\", \"ok\", \"tak\", \"r\", \"x\", \"i\", \"ini\", \"jadi\", \"ada\", \"ke\", \"dan\", \"akan\", \n",
        "\"sang\", \"yang\", \"ada\", \"bagi\", \"untuk\", \"pada\", \"dengan\", \"saat\", \"tidak\", \"nak\", \"tapi\", \"buat\", \"semua\",\n",
        "\"dari\", \"ingin\", \"gara\", \"saat\", \"anak\", \"hey\", \"bro\"])\n",
        "\n",
        "def clean_text(text, stem=False):\n",
        "    tokens = []\n",
        "    for token in text.split():\n",
        "        if token not in stopword:\n",
        "            if stem:\n",
        "                tokens.append(stemmer.stem(token))\n",
        "            else:\n",
        "                tokens.append(token)\n",
        "    return tokens\n",
        "\n",
        "test['judul_baru'] = test['judul'].apply(lambda x: clean_text(x))\n",
        "\n",
        "test.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNRB_Ot12i-H"
      },
      "source": [
        "# Build and Training Model (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train)\n",
        "len(validation)\n",
        "len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36bzSE-KdlBP",
        "outputId": "2d316527-edee-4ed0-cd32-14bc75838c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4231"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVYhwqUeZpOC"
      },
      "outputs": [],
      "source": [
        "train_sentences = train[\"judul_baru\"].tolist()\n",
        "validation_sentences = validation[\"judul_baru\"].tolist()\n",
        "test_sentences = test[\"judul_baru\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PaYk9uZ_ZpOG"
      },
      "outputs": [],
      "source": [
        "vocab_size = 2000\n",
        "embedding_dim = 16\n",
        "max_length = 100\n",
        "trunc_type = \"post\"\n",
        "padding_type = \"post\"\n",
        "oov_tok = \"<OOV>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlfFa8F5ZpOL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "word_index = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G8pjj7zZpOQ"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "training_padded = pad_sequences(train_sequences, maxlen = max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCKDgqaaZpOU"
      },
      "outputs": [],
      "source": [
        "val_sequences = tokenizer.texts_to_sequences(validation_sentences)\n",
        "validation_padded = pad_sequences(val_sequences, maxlen = max_length)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "testing_padded = pad_sequences(test_sequences, maxlen = max_length)"
      ],
      "metadata": {
        "id": "ZGT2U3ionRv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXhzLRzVZpOW"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=128)))\n",
        "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpBHv8qsZpOe"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3D_WAwZZpOl"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "detZFPF2ZpOn"
      },
      "outputs": [],
      "source": [
        "history = model.fit(training_padded, train[\"label\"], validation_data=(validation_padded, validation[\"label\"]), epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDYJdRf7ZpO1"
      },
      "outputs": [],
      "source": [
        "model.save(\"lstm_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaUONtufZpPA"
      },
      "outputs": [],
      "source": [
        "model.save_weights(\"lstm_weights.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training history"
      ],
      "metadata": {
        "id": "N0_ADF8RpHpW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzlk_pOQjH_U"
      },
      "outputs": [],
      "source": [
        "# History training\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Summary acc\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqVI2j6zk9-b"
      },
      "outputs": [],
      "source": [
        "# summmary loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation and prediction"
      ],
      "metadata": {
        "id": "Io5YoHklyWWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = model.evaluate(training_padded, train[\"label\"])\n",
        "val_acc = model.evaluate(validation_padded, validation[\"label\"])\n",
        "test_acc = model.evaluate(testing_padded, test[\"label\"])\n",
        "\n",
        "print(\"train acc: \", train_acc)\n",
        "print(\"val acc: \", val_acc)\n",
        "print(\"test acc: \", test_acc)"
      ],
      "metadata": {
        "id": "zRXnlN2vgJ-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "model = keras.models.load_model(\"lstm_model.h5\")\n",
        "model.load_weights(\"lstm_weights.h5\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "SZLS8522nyma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a14a91a-01b6-461f-e0c6-9606a836ac3d"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 100, 16)           32000     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 100, 16)           0         \n",
            "                                                                 \n",
            " bidirectional_10 (Bidirecti  (None, 256)              148480    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 180,737\n",
            "Trainable params: 180,737\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess\n",
        "#remove punctuation\n",
        "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "def remove_punctuation(text):\n",
        "    no_punct = \"\".join([i for i in text if i not in punc])\n",
        "    return no_punct\n",
        "\n",
        "\n",
        "#remove number\n",
        "def remove_number(text):\n",
        "    no_number = re.sub(r'\\d', '', text)\n",
        "    return no_number\n",
        "\n",
        "\n",
        "#define stemming\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "#define stopwords\n",
        "stopword = stopwords.words('indonesian')\n",
        "stopword.extend([\"c\", \"rp\", \"di\", \"ok\", \"tak\", \"r\", \"x\", \"i\", \"ini\", \"jadi\", \"ada\", \"ke\", \"dan\", \"akan\", \n",
        "\"sang\", \"yang\", \"ada\", \"bagi\", \"untuk\", \"pada\", \"dengan\", \"saat\", \"tidak\", \"nak\", \"tapi\", \"buat\", \"semua\",\n",
        "\"dari\", \"ingin\", \"gara\", \"saat\", \"anak\", \"hey\", \"bro\"])\n",
        "\n",
        "def clean_text(text, stem=False):\n",
        "    tokens = []\n",
        "    for token in text.split():\n",
        "        if token not in stopword:\n",
        "            if stem:\n",
        "                tokens.append(stemmer.stem(token))\n",
        "            else:\n",
        "                tokens.append(token)\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "7DjUZyMrrUej"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predict on new text\n",
        "def new_predict(text, model):\n",
        "  text = text.lower()\n",
        "  text = remove_punctuation(text)\n",
        "  text = remove_number(text)\n",
        "  text = text.encode('ascii', 'ignore').decode('ascii')\n",
        "  text = clean_text(text)\n",
        "  tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)\n",
        "  tokenizer.fit_on_texts(text)\n",
        "  word_index = tokenizer.word_index\n",
        "  text_sequences = tokenizer.texts_to_sequences(text)\n",
        "  padded = pad_sequences(text_sequences, maxlen = max_length)\n",
        "  prediction = model.predict(padded)\n",
        "  avg_pred = prediction.mean()\n",
        "  if avg_pred >= 0.77:\n",
        "    text_label = 'Hoax'\n",
        "  else:\n",
        "   text_label = 'Valid'\n",
        "  return avg_pred, text_label\n"
      ],
      "metadata": {
        "id": "xvEwuqymqTgO"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction example\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "fake_test = pd.read_csv(\"Data_uji.csv\")\n",
        "#text = fake_test['judul'][120]\n",
        "text = \"Jasad Eril, Anak Ridwan Kamil Gubernur Jawa Barat ditemukan tewas di sungai Aare\"\n",
        "print(text)\n",
        "avg_pred, text_label= new_predict(text, model)\n",
        "print()\n",
        "print('-------Prediction result--------')\n",
        "print('This news is', text_label.upper())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86oiVou7on_p",
        "outputId": "343e1ec4-dcaa-48af-882b-eace7f8f095e"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jasad Eril, Anak Ridwan Kamil Gubernur Jawa Barat ditemukan tewas di sungai Aare\n",
            "\n",
            "-------Prediction result--------\n",
            "This news is VALID\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Fake_News_Detector.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "27f6fea6f47ae512550f0b8facdbd035a93e1dd89633f7bf2dd00a2502c71d0d"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}